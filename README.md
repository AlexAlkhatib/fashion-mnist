# ğŸ‘— Fashion MNIST Classification

RÃ©seaux de neurones denses, CNN, Data Augmentation & Transfer Learning


## ğŸ“Œ Description du Projet

Ce projet a pour objectif de **classifier les images du dataset Fashion-MNIST** en 10 catÃ©gories (T-shirt, Trouser, Pullover, etc.).
Plusieurs architectures de Deep Learning ont Ã©tÃ© implÃ©mentÃ©es pour comparer leurs performances :

* **RÃ©seau Dense (Fully Connected Network)**
* **CNN (Convolutional Neural Network)**
* **CNN avec Data Augmentation**
* **Transfer Learning** via **VGG16** (ImageNet)

Le projet inclut :

âœ”ï¸ PrÃ©traitement complet des donnÃ©es
âœ”ï¸ Visualisation des images
âœ”ï¸ Construction et entraÃ®nement de diffÃ©rents modÃ¨les
âœ”ï¸ Comparaison des performances
âœ”ï¸ Visualisation des courbes d'apprentissage
âœ”ï¸ Analyse des prÃ©dictions


## ğŸ“‚ Dataset

Dataset : **Fashion MNIST**
Format : fichiers CSV (train + test)
Dimensions : 28 Ã— 28 pixels, niveaux de gris

CatÃ©gories disponibles :

| Label | Classe      |
| ----- | ----------- |
| 0     | T-shirt/Top |
| 1     | Trouser     |
| 2     | Pullover    |
| 3     | Dress       |
| 4     | Coat        |
| 5     | Sandal      |
| 6     | Shirt       |
| 7     | Sneaker     |
| 8     | Bag         |
| 9     | Ankle Boot  |


## ğŸ§¹ PrÃ©traitement des DonnÃ©es

ğŸ”¹ Chargement du train et test depuis des fichiers CSV
ğŸ”¹ SÃ©paration du train en :

* **50 000 images pour l'entraÃ®nement**
* **10 000 images pour la validation**

ğŸ”¹ Normalisation :

```python
X_train_norm = X_train / 255
```

ğŸ”¹ Encodage One-Hot des labels :

```python
y_train_cat = to_categorical(y_train, num_classes=10)
```

ğŸ”¹ Reshape des images pour CNN :

* Dense : `(N, 784)`
* CNN : `(N, 28, 28, 1)`
* VGG16 : `(N, 28, 28, 3)` + resizing interne en `32Ã—32`


## ğŸ§  ModÃ¨les ImplÃ©mentÃ©s

### ğŸ”¹ 1. RÃ©seau Dense (Fully Connected Network)

Architecture :

* Input 784
* Dense(100, relu)
* Plusieurs couches Dense(20, relu)
* Output Softmax(10)

Optimiseur : **Adam (lr=0.0001)**
Perte : categorical_crossentropy

RÃ©sultat :
Accuracy ~ 87â€“88% sur validation


### ğŸ”¹ 2. CNN Convolutionnel

Architecture :

* Conv2D(8) â†’ MaxPooling
* Conv2D(16) â†’ MaxPooling
* Conv2D(16)
* Flatten
* Dense(16)
* Softmax(10)

Optimiseur : **Adam**

RÃ©sultat :
Accuracy ~ 88â€“89% sur validation


### ğŸ”¹ 3. CNN avec Data Augmentation

Transformations appliquÃ©es :

* RandomFlip
* RandomRotation
* RandomZoom
* RandomTranslation

RÃ©sultat :
Accuracy ~ 76â€“78% (modÃ¨le simple mais robuste, limitÃ© par architecture)


### ğŸ”¹ 4. Transfer Learning â€” VGG16 (ImageNet)

Adaptations :

* Duplication des canaux pour passer en RGB
* Redimensionnement automatique en 32Ã—32
* Couches VGG16 gelÃ©es
* Dense(16) â†’ Dense(10)

ParamÃ¨tres trainables : seulement **8k paramÃ¨tres**
Contrairement aux **14M** de VGG16.

RÃ©sultat :
Accuracy ~ 80% en seulement quelques epochs


## ğŸ“Š Ã‰valuation des ModÃ¨les

Chaque modÃ¨le est Ã©valuÃ© via :

* **Loss**
* **Categorical Accuracy**
* Courbes :

  * Loss vs Val Loss
  * Accuracy vs Val Accuracy

Exemple de dictionnaire de performances :

```python
performances = {
    "RÃ©seau dense": {"Loss": ..., "Accuracy": ...},
    "CNN": {"Loss": ..., "Accuracy": ...},
    "CNN augmentÃ©": {"Loss": ..., "Accuracy": ...},
    "VGG16": {"Loss": ..., "Accuracy": ...}
}
```


## ğŸ” Observation des PrÃ©dictions

Visualisation de quelques prÃ©dictions :

```python
for i in range(10):
    print("Classe prÃ©dite:", labels[np.argmax(y_pred[i])])
    print("Classe vraie  :", labels[np.argmax(y_test_cat[i])])
```

Affichage de lâ€™image correspondante avec Matplotlib.


## ğŸš€ Technologies UtilisÃ©es

* Python 3.x
* NumPy
* Pandas
* Matplotlib / Seaborn
* TensorFlow / Keras
* Scikit-learn


## â–¶ï¸ ExÃ©cuter le Projet

1. **Importer les datasets**
2. **ExÃ©cuter le notebook**

ou lancer les scripts :

```bash
python train_dense.py
python train_cnn.py
python train_cnn_aug.py
python train_vgg16.py
```


## âœ¨ AmÃ©liorations Futures

* Ajout de **ResNet50**, **EfficientNet**, **MobileNetV2**
* Optimisation hyperparamÃ¨tres (Optuna, Keras Tuner)
* Visualisation avancÃ©e (Grad-CAM)
* DÃ©ploiement Streamlit
* Comparaison avec MNIST classique
* Recherche dâ€™architecture automatique (NAS)


## ğŸ‘¤ Auteur

Alex Alkhatib
Deep Learning â€” Classification dâ€™images (Fashion MNIST)


## ğŸ“„ Licence
MIT License
Copyright (c) 2025 Alex Alkhatib
Je peux te le gÃ©nÃ©rer directement.

